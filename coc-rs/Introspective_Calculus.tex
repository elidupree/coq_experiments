\documentclass{article}

\usepackage{tikz}
\usepackage{amsfonts}
\usepackage{amssymb}
%\usepackage[nointegrals]{wasysym}
\usepackage{mathtools}
\usepackage{mathpartir}
\usepackage{nameref}
\usepackage{xcolor}

\usepackage[english]{babel}
\usepackage[autostyle]{csquotes}
\usepackage{amsmath}
\usepackage{wasysym}
\MakeOuterQuote{"}
\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}

%\usepackage[backend=biber,style=numeric]{biblatex}
%\addbibresource{Introspective_Calculus.bib}

\title{The Introspective Calculus}
\author{Eli Dupree}
\date{\today}

\DeclareMathSymbol{\mlq}{\mathord}{operators}{``}
\DeclareMathSymbol{\mrq}{\mathord}{operators}{`'}

\begin{document}
  \maketitle
  
  \section{Introduction}
  
  %This document is a bare-bones explanation of my current definitions of this calculus.
  %I plan to later develop it into a full, polished explanation, once I'm more confident in its soundness.
  
  In type theory, the source of paradoxes (like Russell's paradox and Girard's paradox) is this: First you construct a self-referential claim, then you prove that claim using (rules analogous to) the following axiom of propositional logic, which is unsound for self-referential claims:
  \begin{equation*}
    \label{unsoundaxiom}
    %\tag{implication within hypotheticals, traditional}
    (C \to (A \to B)) \to ((C \to A) \to (C \to B))
    \vspace{0.8em}
  \end{equation*}
  
  Type theories typically avoid this problem by preventing the construction of self-referential claims.
  However, general-purpose computation is intrinsically capable of constructing self-referential claims.
  Thus, any such rules must forbid many programs that would otherwise be valid.

  The present work's innovation is to \emph{allow} self-referential claims, but instead weaken the above axiom.
  % We regard the axiom as \emph{improperly mixing metatheory levels}, for reasons we will explain in Section \ref{firststeps}.
  By using more-limited rules, we can prevent a self-referential claim from being elevated into a self-referential \emph{proof}.
  This allows us to have simple core rules, and a very powerful concept of definitional equality.
  We call our system the Introspective Calculus (IC), because every rule of IC can be cleanly represented as an object within IC; it comes as close as possible to acting as its own metatheory.
  
  \iffalse
  For the following reason:
  
  \begin{itemize}
    \item We say that $(A \to B)$ is true if there is a \emph{chain of valid inferences} that would let you reason from $A$ to $B$.
    \item Thus, $(A \to (A \to B))$ means that if $A$ is true, you can infer that there \emph{exists} a chain of valid inferences from $A$ to $B$ (but if $A$ is not true, there might not be one). \eqref{unsoundaxiom} asserts that this implies $(A \to B)$, i.e. that such a chain already exists. Intuitively, this might seem true: If you first assume $A$, you can conclude that the $(A \to B)$ chain exists, and then apply it to get $B$.
    \item But inferences are metatheoretic objects, and the above is metatheoretic reasoning. So $(A \to B)$ will be true in the metatheory, but this doesn't mean we can automatically internalize it as a provable statement within the theory. Indeed, there \emph{must} be statements that are true, but not provable within the theory; and if we allow self-referential claims, this must be one of them, or we suffer Russell's paradox.
  \end{itemize}

  
  
    \renewcommand{\implies}[1]{\xrightarrow{#1}}
  \newcommand{\lzero}{0}
  \newcommand{\lsucc}[1]{\mathcal{S} #1}
  \begin{equation*}
    \tag{implication within hypotheticals, resilient}
    (C \implies{\lsucc n} (A \implies{n} B)) \implies{\lzero} ((C \implies{\lsucc n} A) \implies{\lzero} (C \implies{\lsucc n} B))
    \vspace{0.8em}
  \end{equation*}
  
  Since the result is one level higher than $A \implies{n} B$, it cannot be used later to prove the same $A \implies{n} B$ claim that it's based on. This prevents a self-referential claim from being elevated to form a self-referential \emph{proof}.
  
  This protection allows us to remove the other limitations of type theories.
  In particular, the source of the name "Introspective Calculus" is that every rule of IC can be abstracted over within IC.
  
  Section \ref{fundamentals} (\textit{\nameref{fundamentals}}) gives a formal definition of IC.
  
  \fi
   
  \section{The introspection principle}\label{firststeps}
  
  For a proof system to be fully general, it needs to be able to analyze everything – including itself. Our design will be guided by this principle, which I call the \textbf{introspection principle}:
  
  \begin{center}
    For anything we define in the metatheory, there should be formulas that represent\footnote{"But," you say, "how do you know that the theoretic definition 'represents' the metatheoretic definition?" Well, you verify it by a metatheorem saying that the two definitions have an exact correspondence. More on this later.} it within the theory.
  \end{center}
  
  Like many proof systems, we will define a grammar of formulas, and a collection of inference rules that can be used to judge some of those formulas "true". Therefore, by the introspection principle, we need to define formulas that \emph{represent} inference rules and truth judgments.
  
  As it turns out, once we have done this, we will have essentially completed the system! However, getting there will take some careful design.
  
  \subsection{The liar paradox}
  
  First, let's be precise about the limits of the introspection principle, by showing a temptation we need to avoid.
  
  Suppose we define $(A \vdash B)$ as "if you assume $A$, then you can derive $B$ according to the rules of IC." By the introspection principle, $(A \vdash B)$ must be representable as a formula; and clearly, if you have proven the formulas $A$ and $(A \vdash B)$, then $B$ had better be provable.
  
  \newcommand{\strongmp}{(A\ \mathrm{and}\ (A \vdash B)) \vdash B}
  All of that is fine; but at this point, it may be tempting to say that $\strongmp$ is, itself, a \emph{rule of IC}. However, if we do this, IC will succumb to the liar paradox and be unsound!
  
  Here's how:
  
  First, we define absurdity: $\bot$ (read as "false") is a formula that says "all formulas are true".
  (Clearly we don't want this to be true.)
  Then, we can construct a version of the liar paradox, where:
  
  \newcommand{\name}[1]{\operatorname{\texttt{#1}}}
  \begin{equation*}
    \name{liar} \equiv (\name{liar} \vdash \bot)\\
  \end{equation*}
  
  (It may not be obvious that this should be possible; but we assert that it is.
  We will later show how self-referential formulas arise naturally from how we define computation.
  For now, simply assume that they are just as legitimate as other formulas.)
  
  We now apply our rule, with $(A := \name{liar})$ and $(B := \bot)$, to obtain 
  
  \begin{equation*}
    (\name{liar}\ \mathrm{and}\ (\name{liar} \vdash \bot)) \vdash \bot
  \end{equation*}
  
  But $(\name{liar}\ \mathrm{and}\ (\name{liar} \vdash \bot))$ is the same thing as just $\name{liar}$, so this reduces to $(\name{liar} \vdash \bot)$ – which reduces to $\name{liar}$! And since $\name{liar}$ is now proven, we can derive $\bot$, which makes the system unsound.
  
  I've glossed over some details here, but there's no clean way to fix it by fiddling with the details. The conclusion is this: The rule $\strongmp$ cannot be a rule of any system where $\name{liar}$ is expressible, so it cannot be a rule of IC.
  
  "But," you say, "That rule looks just like \emph{modus ponens}, one of the basic rules of countless systems of logic!" Indeed it does! The problem here is that we've made this rule generalize over everything you can "derive according to \emph{the rules of IC}" – a set which includes itself. Other systems get away with this, because even if a rule is infinitely recursive, it won't "pull falsehoods from infinity" unless you use it on an infinitely recursive formula. But in IC, we allow infinitely recursive formulas – so we must forbid infinitely recursive rules!
  
  What do we do about this?
  
  In IC, we will have two kinds of rules:
  \begin{itemize}
    \item The \textbf{core rules}, a complete set of rules which define the basics of how inference works, and do not include anything like $\strongmp$. To do basic logic, we will instead use the more limited rule of transitivity.
    \item Optionally, a set of \textbf{extension rules}, an open-ended hierarchy of rules much like $\strongmp$, except that each one only generalizes over the earlier rules in the hierarchy, rather than all of IC.
  \end{itemize}
  
  Here's some intuition for why $\strongmp$ isn't among the core rules: It isn't inherent to how inference works! It essentially says "anything that's been proven in the theory, is also true in the metatheory" – which is, of course, a desirable property for proof systems to have, but isn't a requirement for \emph{being a proof system in the first place}, only for being a \emph{sound} proof system. The core rules are for describing \emph{all} proof systems, not just sound ones. The core rules (we believe) are sound, so they do have this property, but we will confirm that with a metatheorem about the core rules, rather than asserting it as a rule of the core rules.
  
  \section{The core rules of IC}
 
  \subsection{Formulas and inference}
  
  \newcommand{\id}{\name{id}}
  \newcommand{\const}{\name{const}}
  \newcommand{\default}{\name{default}}
  \newcommand{\fuse}{\name{fuse}}
  
  \newcommand{\atomemptyset}{\name{empty\_set}}
  \newcommand{\atomsingleton}{\name{singleton}}
  \newcommand{\atomin}{\name{in}}
  \newcommand{\atomunion}{\name{union}}
  \newcommand{\atomconcludes}{\name{concludes}}
  \newcommand{\atomall}{\name{all}}
  \newcommand{\atominfrule}{\name{rule}}
  \newcommand{\atomimplies}{\name{implies}}
  \renewcommand{\emptyset}{\varnothing}
  \newcommand{\singleton}[1]{\{#1\}}
  \newcommand{\union}{\cup}
  
  \newcommand{\and}{\wedge}
  \newcommand{\all}{\bigcup}
  \newcommand{\atomequals}{\name{equals}}
  \newcommand{\equals}{\equiv}
  \newcommand{\concludes}{\leadsto}
  \newcommand{\infrule}{\vdash}
  
  % Whenever you're defining a formal system, you have to explain it using statements that aren't part of the system (because it's not defined yet).
  % Even though the introspection principle will ask us to make internal representations of those external statements, we still find it useful to be explicit about which things are external.
  % If we want to implement IC as a computer system, the external part is the part which we'd have to implement in the host language, rather than implementing with IC itself.
  
  % At the top level, we will define two things: A grammar of raw formulas, and a system of inference which allows us to conclude that some of these formulas are \textbf{true}.
  
  The raw grammar of IC is:
  
  \begin{align*}
    F &\to \atomequals \mid \const \mid \fuse \mid FF \\
  \end{align*}
  
  Adjacency means function application: The formula $AB$ is the function $A$ applied to the input $B$. We sometimes use parentheses to specify the order of operations; when we don't, it is left-associative ($ABC$ means $(AB)C$).
  
  All propositions will be represented by nested applications of these elementary functions.
  
  That said, we would \emph{like} to write propositions using mathematical notation instead.
  (This paper would be hard to read otherwise.)
  So, for the human reader's benefit, we will often write formulas using fancier "notations", which are convenient shorthands which expand to raw formulas of IC.
  To start with, we'll define a notation for equality statements:
  
  \begin{align*}
    (A \equals B) &:= (\atomequals A\, B)\\
  \end{align*}
  
  But as far as the internal logic is concerned, only the raw formulas exist.\footnote{"But," you say, "doesn't be introspection principle ask that if you're defining notations in the metatheory, you should define a representation of them within the theory?" Well, yes – but it's not needed for explaining the \emph{core calculus}, which is the main job of \emph{this paper}. A full programming language, which I plan to build around this core calculus, would naturally be able to implement functions that convert text into token-trees and token-trees into formulas of IC, and others such inconveniences of interfacing between raw mathematical objects and the human reader.}  
  
  Having defined the grammar, we need only define our explicit list of inference rules. 
  All external inference rules (which are \emph{not} formulas, although we will later make formulas to represent them) will be written in the usual form:
  
  %\newcommand{\presep}{\hspace{1.8em}}
  %\newcommand{\globalrule}[2]{\frac{#1}{#2}}
  \newcommand{\presep}{,\,}
  \newcommand{\globalrule}[2]{#1 &\vdash #2}
  
  \begin{align*}
    \globalrule{Premises\dots}{Conclusion}\\
  \end{align*}
  
  where $Premises\dots$ and $Conclusion$ are formulas, except that they may contain metavariables written with the capital Latin letters $A, B, C, \dots$ which range over all raw formulas. For any of our explicit rules and any concrete values of the metavariables, if an external judge (such as a human mathematician, or a computer program) has been convinced of all the premises, the rule can be used to convince them of the conclusion.
  
  We must now define some inference rules that let us internalize the concept of inference rules.


  \iffalse

  \subsection{Truth predicates}
  
  [since we have multiple concepts of truth, we need to formalize them:]
  
  A \textbf{truth predicate} is a predicate on propositions – a function that takes propositions and classifies them as "true" or not. Formally, its inputs are propositions, and its outputs are also propositions. If you have a truth predicate $\mathbb{T}$ and a proposition $A$, then if the proposition $\mathbb{T} A$ is \emph{true}, we say that $\mathbb{T}$ believes $A$; if $\mathbb{T} A$ is \emph{not true}, we say that $\mathbb{T}$ does not believe $A$. (But it doesn't necessarily believe that $A$ is false.)
  
  To define the first truth predicate in our hierarchy, we will state some rules of inference, and say that the first truth predicate is the \emph{minimal predicate that obeys those rules} – that is, the set of statements that are forced to be true by those inference rules.
  
  So how do we formalize inference rules? An inference rule is not just a proposition, which makes a single claim that may be true or false – rather, it's a description of requirements for what must be "true", which some truth predicates obey, and some disobey.
    
  Thus, we define an inference rule as a \emph{predicate on truth predicates} – a function that takes truth predicate and classifies whether the truth predicate obeys them or not. Formally, its inputs are truth predicates, and its outputs are propositions\footnote{At this point, the reader may wonder: "If a proposition is just a function that returns more propositions, when does it end?" This is a misconception. Just like in the lambda calculus, everything is a function forever, and that's okay.}. If you have a rule $R$ and a truth predicate $\mathbb{T}$, then if the proposition $R \mathbb{T}$ is \emph{true}, we say that $\mathbb{T}$ obeys $R$; if $R \mathbb{T}$ is \emph{not true}, we say that $\mathbb{T}$ does not obey $R$.
  
  Before we can start defining concrete rules, we need to formalize how we define functions.
  
  \fi
  
  \subsection{Equality}
  
  $\atomequals$ is the relation of definitional equality. Informally, if $A \equals B$, then $A$ and $B$ are distinct formulas that refer to the same mathematical object. Equal formulas can be substituted for each other at any position within a larger formula:
  
  \begin{align*}
    \tag{symmetry}\label{eq_sym}
    \globalrule{A \equals B}{B \equals A} \\
    \tag{transitivity}\label{eq_trans}
    \globalrule{A \equals B \presep B \equals C}{A \equals C} \\
    \tag{substitute in left}\label{subst_l}
    \globalrule{A \equals B}{AC \equals BC} \\
    \tag{substitute in right}\label{subst_r}
    \globalrule{A \equals B}{CA \equals CB}
  \end{align*}
  
  (Reflexivity ($A \equals A$) is also true, but it will be derivable from the other rules.)
  
  Here's some intuition on what things "count as equal":
  
  Equality is the only kind of proposition in IC. Loosely speaking, there are two kinds of formulas: Propositions (of the form $(A \equals B)$), and functions (which take one formula and return another). Propositions are not functions; technically, you can apply any formula to any other, but formulas like $(A \equals B)C$ are nonsense, though they are technically permitted.
  
  We want the following things to be equal:
  
  \begin{itemize}
    \item Function applications $(FX)$ should be equal to their outputs (the result of applying $F$ to $X$).
    \item The point of functions is to express input-output mappings, so functions should be equal to other functions when they give the same outputs for every input: if $FX = GX$ for all $X$, then $F = G$. This is called "function extensionality", because the input-output mappings are the "extensional properties" of the function (as opposed to its "intensional properties", which are the details of how you define it).
    \item The point of propositions is to express logical truths, so propositions should be equal to other propositions when they are logically equivalent – that is, when a judge couldn't possibly believe one of them without also believing the other, even if the judge may hold hypothetical beliefs. This turns out to mean that $(A \equals B) \equals (C \equals D)$ should be true exactly when $(A \equals B)$ and $(C \equals D)$ can be derived from each other by the core rules only.
  \end{itemize}
  
  The above descriptions are informal; we will succeed in formalizing them, but it will be more complex than just asserting it.
  
  Incidentally, that last point means that all true propositions are equal to each other. This means we can define $\top$ (read as "true"), a canonical true proposition, which is equal to all other true propositions. We can pick a "default formula" and implement $\top$ as $(\default\equals\default)$; we arbitrarily choose for $\default$ to equal $\const$, but write it as $\default$ to emphasize that it doesn't really matter what it is.
  
  \subsection{Functions}

  To internalize the concept of metavariables, we will implement arbitrary functions. To do this, we define two fundamental functions, or "combinators", that can be composed to construct any other function.\footnote{Readers may recognize this as the SKI combinator calculus. My "const" is the K combinator, and my "fuse" is the S combinator. These names have about the same meanings as the German words (K)onstanzfunktion and Ver(s)chmelzungsfunktion, for which K and S are named in Schönfinkel's original paper. Before I learned of SKI, I had to reinvent it for myself; but after learning of it, I renamed my "fuse" combinator to be more aligned with its naming scheme, because my original name, "apply", was no less confusing.} $\const$ takes two arguments and returns the first (or, equivalently, takes one value and returns a function which ignores its argument and returns that value); $\fuse$ takes two functions and a value, passes that value to \emph{both} functions, then applies the first output to the second output. We can write inference rules to describe this behavior:
  
  \begin{align*}
    \tag{definition of const}\label{def_const}
    \globalrule{}{\const A\, B \equals A} \\
    \tag{definition of fuse}\label{def_fuse}
    \globalrule{}{\fuse A\, B\, C \equals (AC)(BC)}
  \end{align*}
  
  We call these the "unfolding" rules; the left-hand side is a function application, which you can "unfold"\footnote{Existing literature calls this process "reduction" ("beta-reduction", in the case of the lambda calculus); I personally call it "unfolding", since "beta" is meaningless to the uninitiated, and "reduction" misleading (unfolding can make formulas larger and more complicated). } to the right-hand side, which is what the function returns. By using the substitution rules, you can unfold function-applications that are in the subformulas. By using transitivity (and symmetry), you can perform multiple unfolding steps, or unfold within the left- or right-hand side of a proposition. Combined, these allow you to do arbitrary computation.
  
  (Readers may note that, by allowing arbitrary computation here, we've made equality undecidable. This is fine and expected.)

  \newcommand{\nameabst}[1]{#1 \Rightarrow}

  Of course, usually, we don't want to write functions as giant piles of $\const$ and $\fuse$ – we want to write them with named arguments. For this, we define a notation $\nameabst{x} B$ (read as "x goes to B" or "lambda x, B"\footnote{Although many systems write this as "$\lambda$" (lambda), after the lambda calculus, we do not. One of my eventual goals is to introduce proof systems to a more general audience of programmers; the notation \texttt{=>} will be familiar to users of JavaScript, at least, and it hints at the meaning of transforming one value to another, while "$\lambda$" is meaningless. [TODO: citation for the meaninglessness of $\lambda$]}), where $B$ is a formula except that it may contain usages of the name $x$, as if they are subformulas. This expands to a bunch of combinators where $(\nameabst{x} B) C$ returns "$B$ except the usages of $x$ are replaced with $C$". (How do you do the conversion? It's called "abstraction elimination" and it's a well-known technique of the SKI combinator calculus; TODO put a full explanation here.)
  
  Next, we want to define universal statements. Since all propositions are equalities, all universal statements would be of the form $\forall x, P(x) = Q(x)$. In IC, we express this as an equality between functions: it's as simple as $(P \equals Q)$!
  
  However, there's some complexity when we want to represent statements with multiple variables. One \emph{can} do this using functions with multiple arguments, which is straightforward; but it turns out to make the metatheorems harder, because then you have to generalize over the number of arguments. To simplify the metatheorems, we want to work with functions that take a single argument, which is a list.
  
  So what's a list?
  
  \subsection{Argument lists}
  
  A list is a chain of pairs. So what's a pair?
  
  In functional programming, there's no built-in way to return multiple values from a function, but there \emph{is} a built-in way to \emph{pass} multiple values. So to return multiple values, you return a single function which \emph{will} pass multiple values into \emph{another} function, which will be specified later. That is:
  
  \begin{align*}
    (A, B) &:= (\nameabst{f} f A B)\\
  \end{align*}
  
  or equivalently:
  
  \begin{align*}
    (A, B) &:= (\fuse\, (\fuse \id\, (\const A))\, (\const B))\\
  \end{align*}
  
  ($\id$ is the identity function, which can be implemented as $(\fuse\const\default)$.)
  
  If you have a pair $p$, and you want to extract just the first element, you can write $p(\nameabst{a} \nameabst{b} a)$, also known as $(p \const)$. If you want to extract just the second element, you can write $p(\nameabst{a} \nameabst{b} b)$, also known as $(p (\const \id))$.
  
  In general, we'll be working with pair-chains of the form $(A, (B, (C, \dots (K, \default) \dots)))$. We need to be able to select the $n$th element of such a chain. This can be accomplished with these two functions:
  
  \begin{itemize}
    \item $\name{top} := \nameabst{l} l \const$, which selects the first element of $l$ (the head of the chain).
    \item $\name{pop\_in} := \nameabst{f} \nameabst{l} l (\const f)$, which applies a continuation $f$ to the tail of the chain $l$.
  \end{itemize}
  
  So, for example, to select the third element, you apply $(\name{pop\_in}\, (\name{pop\_in} \name{top}))$. We also define a shorthand notation: $l[0]$ means $(\name{top} l)$, $l[1]$ means $(\name{pop\_in} \name{top}) l$, and so forth.

  We can now give the full method of internalizing a "proposition that contains metavariables".
  
  \begin{itemize}
    \item First, you pick an order for the variables. This order is essentially an arbitrary implementation detail; in my code, I automatically choose whichever order gives the smallest resulting formula.
    \item Then, you wrap each side in $(\nameabst{l})$, and replace each usage-site with the appropriate selection function applied to $l$.
  \end{itemize}
  
  For example, $(\const A\, B \equals A)$ becomes $(\nameabst{l} \const l[0]\, l[1]) \equals (\nameabst{l} l[0])$.
  
  
  \subsection{Specialization}
  
  Let's talk about how to \emph{use} one of these list-based propositions.
  
  Suppose you know that the proposition $(\nameabst{l} \const l[0]\, l[1]) \equals (\nameabst{l} l[0])$ is true, but you have \emph{concrete} formulas $x$ and $y$, and you want to know that $(\const x\, y \equals x)$ is true. This is called "specialization", and it's already possible with the rules we have already defined. First, you use \eqref{subst_l} to obtain $(\nameabst{l} \const l[0]\, l[1])(x,(y,\default)) \equals (\nameabst{l} l[0])(x,(y,\default))$. Then all you need is to unfold in each side, until you get $(\const x\, y \equals x)$.
  
  This means it can already do everything that our external rule, \eqref{def_const}, can do – and more, because it makes the universal statement available to internal logic. We will not need to assert any more core rules that contain metavariables, because we can now assert them as raw formulas, using lists. (Although we can't throw out the rules we already have, because they're needed for performing specialization in the first place.)
  
  So, what else might we want to do using axioms?
  
  We may also want to specialize an axiom with values that \emph{themselves contain metavariables}. For example, if $(\const A\, B \equals A)$ is true for all values of $A$ and $B$, then we should also be able to prove that $(\const (\fuse A B)\, (\const C) \equals (\fuse A B))$ is true for all values of $A$, $B$ and $C$. I call this "partial specialization", and it is \emph{not} possible using just the rules we have already defined; we must assert some new axioms to make it possible.
  
  The following axioms do the job. These probably aren't the minimal axioms, but they are the ones that make my metatheorems the simplest, and a computer can trivially verify that each of them is a true extensional equality. We assert the list-form of each of these axioms:
  
  \begin{align*}
  \const A B &\equals A\\
\fuse A B C &\equals (A C) (B C)\\
\fuse (\const A) (\const B) &\equals \const (A B)\\
\fuse (\const (\const A)) B &\equals \const A\\
\fuse (\const (\fuse A B)) C &\equals \fuse (\fuse (\const A) C) (\fuse (\const B) C)\\
\fuse (\const (\nameabst{l} l \const)) (\nameabst{l} (Hl, Tl)) &\equals H\\
\fuse (\const (\nameabst{l} l (\const A))) (\nameabst{l} (Hl, Tl)) &\equals \fuse (\const A) T\\
   \end{align*}
   
  (My metatheorems are currently only implemented in code, not here in this paper.)
 
  \subsection{Implication}
  
  One thing remains to internalize: the concept of premises.
  
  Let's start by defining the logical connective, $\and$ (read as "and"). This can only be applied to propositions, so the operands must syntactically contain $\equals$:
  
  \begin{align*}
    ((A \equals B) \and (C \equals D)):= ((A,C) \equals (B,D)) 
  \end{align*}
  
  Intuitively, "if two pairs are the same, then their corresponding members are the same". Let's also show this rigorously. For this to be a good definition, we should be able to prove these inferences:
  
  \begin{align*}
    \globalrule{(A \equals B) \presep (C \equals D)}{((A \equals B) \and (C \equals D))} \\
    \globalrule{(A \equals B) \and (C \equals D)}{(A \equals B)} \\
    \globalrule{(A \equals B) \and (C \equals D)}{(C \equals D)} \\
  \end{align*}
  
  To prove the first, suppose we know $(A \equals B), (C \equals D)$. We can start with $((A,C) \equals (A,C))$ by reflexivity. By \eqref{subst_l} and unfolding, we can convert $(A \equals B)$ into $((A,C) \equals (B,C))$, and convert $(C \equals D)$ into $((B,C) \equals (B,D))$. These can be joined together by \eqref{eq_trans} to obtain $((A,C) \equals (B,D))$, which is the goal.
  
  The other two are solved by using \eqref{subst_r} with the functions that select the first or second element of the pair.
  
  We can now define implication with one premise, $\to$ (read as "implies"):
  
  \newcommand{\prop}[1]{\mathbf{#1}}
  
  \begin{align*}
    (\prop{A} \to \prop{B}) := (\prop{A} \equals (\prop{A} \and \prop{B}))
  \end{align*}
  
  Assume here that "$\prop{A}$" and "$\prop{B}$" represent propositions: formulas of the form $X \equals Y$, for some $X$ and $Y$. The full, less-readable form, is $((A \equals B) \to (C \equals D)):= ((A \equals B) \equals ((A \equals B) \and (C \equals D)))$.
  
  Again, let's show why this is a good definition of implication.
  
  We've claimed that equality should mean "mutual derivability by the core rules"; if it does, then $\to$ now means one-directional derivability by the core rules.
  After all, if $\prop{A}$ lets you derive $\prop{B}$, then it also lets you derive $(\prop{A} \and \prop{B})$; and if you know $(\prop{A} \and \prop{B})$, you can derive $\prop{A}$; so $\prop{A}$ is mutually derivable with $(\prop{A} \and \prop{B})$.
  Conversely, if you first know that $\prop{A}$ and $(\prop{A} \and \prop{B})$ are mutually derivable, you can reason from $\prop{A}$ to $(\prop{A} \and \prop{B})$ and then to $\prop{B}$.
  
  What remains to show is that equality is "mutual derivability by the core rules". This is not yet established by the rules we've asserted so far. We need to add one additional unary rule, and several axioms. We would like for the rule to be:
  
  \begin{align*}
    \tag{substitute in conjunction}\label{subst_c1}
    \globalrule{\prop{A} \equals \prop{B}}{(\prop{A} \and \prop{C}) \equals (\prop{B} \and \prop{C})} \\
  \end{align*}
  
  However, this doesn't automatically generalize. We need to assert the generalized form, something like this:
  
  \begin{align*}
    \tag{substitute in conjunction}\label{subst_c}
    \globalrule{(\nameabst{l} \prop{A}l) \equals (\nameabst{l} \prop{B}l)}{(\nameabst{l} \prop{A}l \and \prop{C}l) \equals (\nameabst{l} \prop{B}l \and \prop{C}l)} \\
  \end{align*}
  
  This is slightly questionable notation; if $\prop{A}$ denotes a formula $A_0 \equals A_1$, then $\prop{A}l$ denotes $A_0l \equals A_1l$, rather than the nonsensical $(A_0 \equals A_1)l$ as you might expect. The full rule, if we must, is:
      
  \begin{align*}
    \tag{substitute in conjunction}\label{subst_c3}
    \frac{(\nameabst{l} (Al \equals Bl)) \equals (\nameabst{l} (Cl \equals Dl))}{(\nameabst{l} ((Al,El) \equals (Bl,Fl))) \equals (\nameabst{l} ((Cl,El) \equals (Dl,Fl))))} \\
  \end{align*}
  
  Again, I've established it by a metatheorem [note: I haven't actually rigorously completed this yet; these axioms might get tweaked], which makes use of the following additional axioms. Again, one can verify that these axioms are valid equalities, in that they only make propositions equal if they're already mutually derivable. And again, we assert the list form of each:
  
  \begin{align*}
    (A \and B) &\equals (B \and A)\\
    ((A \and B) \and C) &\equals (A \and (B \and C))\\
    ((A \equals B) \and (B \equals C)) &\to (A \equals C)\\
  \end{align*}
  
  And with that, the core rules of IC are finished!
  
  \section{Extensions of IC}
  
  We say that the statement is "true" if-and-only-if it is provable by the core rules. Thus, we will not add any more rules that \emph{make new statements true}. However, this doesn't mean we are done adding rules! Consider the following:
  
  \begin{align*}
    \globalrule{(A \equals B) \presep A}{B} \\
  \end{align*}
  
  I have proved by metatheorem that if there are proofs of $(A \equals B)$ and $A$, then there is a proof of $B$. However, this isn't an inference that is allowed by the core rules: my metatheorem works by induction on the structure of the proofs, rather than by \emph{deriving} the conclusion from the premises. Indeed, we're not allowed to make this derivable in the core rules: if we assert $(((A \equals B) \and A) \to B)$, then IC succumbs to the liar paradox. (We can even prove so within IC!)
  
  However, there's nothing stopping us from adding it as a rule of inference. Formally, the rule we will assert is this, which is equivalent to the above by transitivity:
  
  \begin{align*}
    \tag{strengthen by 1}\label{strengthening_1}
    \globalrule{(\top \equals (A \equals B))}{(A \equals B)} \\
  \end{align*}
  
  (Note that $(A \equals B) \to (\top \equals (A \equals B))$ was already a true statement, but the converse is not.)
  
  Of course, the introspection principle immediately says: We must now make an internal representation of "derivability by the core rules \emph{plus \eqref{strengthening_1}}".
  
  [There's a whole ordinal hierarchy here, but this is where this paper stops for now, because I need to finish the core metatheorems before I'll be ready to write up this part]
  
  % first step of small hierarchy:
  %\begin{align*}
  %  (A \leadsto B) := (A \to (\top \equals B)) \\
  %\end{align*}
  
  
  
  \iffalse
  
  % fold-equivalence\footnote{The literature calls this concept "beta-equivalence"; I personally call it "fold-equivalence", because I use the term "unfolding" rather than "beta-reduction" for the steps, since "beta" is meaningless to the uninitiated, and "reduction" misleading (unfolding can make formulas larger and more complicated). }, the relationship between a function-application and its output.
  
  
    
  \section{Derivable/admissible rules}

  [the rest of this paper will be guided by the following belief: "the provable statements are exactly the ones that can be concluded by $\deduction$" / "the rules we've written so far are sufficient to conclude any true statement, and conclude only true statements." $\deduction$ ]
  
  [so what's missing? But this: these rules do not permit/implement all valid inferences. To motivate our next discussion, let's consider some examples of valid inferences that $\deduction$ can't make]
  
  [first, the very fact that all provable statements are provable to be concluded by $\deduction$, and vice versa:]
  
  [important to note that adding these rules doesn't add any \emph{conclusions} that weren't possible already]
   
  [this suggests an infinite hierarchy of inference rules – in fact, it will grow into an ordinal hierarchy – but we'll come back to that]
  
  [our second example, implication/hypothetical reasoning: we would like to say that if you can conclude something by taking an additional axiom, and that axiom was true unconditionally, then the conclusion is true]
  
  \renewcommand{\implies}[1]{\xrightarrow{#1}}
  
  \begin{align*}
    A \implies{R} B := (R \union (\forall x, \singleton{(x \in A) \infrule x})) \concludes B\\
  \end{align*}
  [the rule:]
  \begin{align*}
    \tag{hypothetical reasoning}\label{hyp}
    \globalrule{A \implies{R} B \presep (R \concludes A)}{R \concludes B}\\
  \end{align*}
  [and in fact, if you can argue something hypothetically, it's just as good as a rule, since the "only thing a rule can do" is to take A to B:]
  \begin{align*}
    \globalrule{A \implies{R} B \presep (R \union \singleton{A \infrule B}) \concludes C}{R \concludes C}
  \end{align*}
  
  [rather than adding new rules ad hoc, we would like a more principled way to describe what kinds of rules are valid. But first:]
  
  \subsection{Interlude: How this solves the liar paradox}
  
  [the liar paradox must specify under which rules it's negating itself, $\name{liar}R \equiv (\name{liar}R \implies{R} \bot)$]
  
  [observe that $R = \deduction$ does not choke on this, because $\deduction \union \singleton{A \infrule B}$ only believes that $\deduction \concludes \bot$, but does not actually conclude $\bot$ itself , because it doesn't include the rule [eqref]. Nor does D2, because it doesn't include the rule [same rule but applying to D2]!]
  
   if you "close the loop" on the ordinal hierarchy ($(A \implies{G} B, A \infrule B) \in G$), the liar paradox starts to take effect, and we can conclude $G \concludes \bot$ by plugging in $\name{liar}G$ [show how]. This is perfectly safe and satisfying, as this means we are capable of proving $(\deduction \concludes (G \concludes \bot))$ – or, to phrase it another way, "a ruleset that believes `all my own beliefs are true', is unsound"!]
   
  [Therefore, IC's take on the liar paradox is: self-referential statements are fine, and any system that chokes on them is improperly, implicitly using self-referential \emph{rules of inference}!]
  
  
  
  [we believe that the above rules allow you to prove all interesting mathematical statements, but maybe that's not very satisfying, because you do it by constructing other formal systems within this one. We would like to make some more rules so that you can do more stuff more intrinsically
  
  
    
  In particular, even if $(A \equals B)$ is true, $A \to B$ is not required to be true – and indeed, unlike the usual propositional logic, our system does not require that $A \to A$ be true! (What does this mean? Well, $A \to A$ is traditionally equivalent to $(\neg A \vee A)$; and some paradoxical statements are neither true nor false. $A \to A$ can't be false, but if $A$ is neither true nor false, $A \to A$ is also neither true nor false.)
  

  
  The introspection principle asks that we define formulas to represent inference rules.
  In some sense, this is the \emph{only} thing we need to do – by the time we're done representing inference rules, the theory will be powerful enough to represent everything else.
  However, when we try to define the concept of inference rules from a completely blank slate, we quickly see that it's built out of several sub-concepts:
  \begin{itemize}
    \item \textbf{Unordered sets} of premises, which are other formulas.
    \item \textbf{Variables} (the A and B above), which express that you can inject arbitrary formulas into particular locations within the inference rule, and say that the rule exists for all such values.
    \item Finally, the fact that you can combine multiple inference rules to draw further conclusions.
  \end{itemize}
    
  
  This continues infinitely, and the same rules must exist on every level.\footnote{Propositional logic avoids this by making all later relations the same as the second one, but accepting that they will have different rules than the first.}
  
  \\
  
  \textbf{Definition.} IC has $(\deduction\ (\to)\ (\to))$ as inference rules.
  
  \textbf{Definition.} IC has $(\deduction\ (\to)\ (\to))$ as a true statement, i.e. IC has $(\top \to \deduction\ (\to)\ (\to))$ as an inference rule.
  \\
  
  "But wait," you say, "if we can just plug in $(\to)$ as both inputs, why did we need to keep them separate?"
  
  Back to that in a minute. First, let's explore what statements count as true within the system so far.
  
  \subsection{Is \emph{modus ponens} true?}
  
  One may view a formal system is describing a \emph{set of true statements}. It does this by stating inference rules, which are \emph{constraints} on the set of true statements. In particular, inference rules are "positive constraints" – "if these premises are true, this conclusion must be true" – and never say that a statement must \emph{not} be true. Rather than having negative constraints, we just say that we're only interested in the set of statements that are \emph{forced} to be true by the inference rules – also known as the \emph{minimal relation obeying the inference rules}, or \emph{postulating induction on the structure of proofs}. And we hope that our system is \emph{consistent}, meaning that it does not force \emph{all} statements to be true.
  
  IC has an additional desire: Each true statement should represent a correct constraint on the set of true statements. And ideally, all correct constraints would also be true statements. But unfortunately, some constraints are self-incompatible: They are only correct if they are not also true statements (or if all statements are true). So we have to be slightly stricter about what statements can be "true".
  
  Let's consider the statement "Each true statement should represent a correct constraint on the set of true statements." By the introspection principle, we should be able to represent this statement in IC. Indeed, we can already represent the statement – and it is \emph{modus ponens!}
  
  "But," you say, "how does \emph{modus ponens} mean that?"
  
  Suppose you have a true statement $A \to B$. If we view this as a derived inference of IC, it is $\top \to (A \to B)$. If we also know that \emph{modus ponens}, also known as $(A \wedge (A \to B) \to B)$, is an inference of IC, then we can apply the chain rule – satisfying \emph{modus ponens}'s need for the premise $(A \to B)$ – and get $(A \wedge \top \to B)$, which reduces to $A \to B$, now on the level of an inference rather than a true statement. Thus, \emph{modus ponens} can be used to turn any true statement into an inference. This reflects our intent for the language; we must assert that it is a correct constraint.
  
  But what happens if we make it a true statement?
  
  \subsubsection{Russell's Paradox}
  
  First, we'll need some preliminaries.
  
  We define $\bot$ (read as "false") to equal $(\bigwedge \id)$, the proposition that all propositions are true. Clearly, this cannot be true in a consistent system.
  
  We would like to construct a statement $P$ such that $P \equiv P \to \bot$. To do this, we use Russell's Paradox, the "set of all sets which do not contain themselves". By convention, we represent \emph{sets} as predicates, and say that a set $S$ "contains" any $x$ for which $S x$ is true. So the "set of all sets which do not contain themselves" is:
  
  \begin{align*}
    R := \nameabst{x} x x \to \bot
  \end{align*}
  
  Now, our $P$ is simply $RR$:
  
  \begin{align*}
    P &:= RR\\
      &\equiv (\nameabst{x} x x \to \bot)R\\
      &\equiv RR \to \bot\\
      &\equiv P \to \bot\\
  \end{align*}
  
  Armed with this paradoxical statement, we can specialize \emph{modus ponens} with $A := P$ and $B := \bot$. The following statement is true, even if we do not assume \emph{modus ponens}:
  
  \begin{align*}
    modus\ ponens &\to (P \wedge (P \to \bot) \to \bot)\\
  \end{align*}
  
  But wait – $P \to \bot$ is just $P$, and $P \wedge P$ is just $P$, so this reduces:
  
  \begin{align*}
    modus\ ponens &\to (P \wedge (P \to \bot) \to \bot)\\
    modus\ ponens &\to (P \wedge P \to \bot)\\
    modus\ ponens &\to (P \to \bot)\\
    modus\ ponens &\to P\\
  \end{align*}
  
  If \emph{modus ponens} is both an inference rule and a true statement, we can now specialize the inference rule with $A := modus\ ponens$ and $B := P$, and thus infer that $P$ is true; and with one more use of the inference rule, we can infer that $\bot$ is true, and the system is inconsistent.
  
  Thus, \emph{modus ponens} is precisely one of our "self-incompatible constraints" – a constraint that is correct, but must not be a true statement! I choose to interpret this as \emph{modus ponens} being an "improper" rule of deduction, because of how it mixes truths with inferences, unlike all the rules in $\deduction$. Much of our remaining rules will be devoted to getting as close as possible to having \emph{modus ponens} be true, by adding a series of limited, safer versions of it.
  
  
    
  %(A \wedge (A \to B) \vdash B)
  
  \subsection{Induction on proof structure}
  
  Consider again the statement "Statements are only true if they're forced to be true by the inference rules." As with \emph{modus ponens}, we regard it to be true from the outside perspective. How shall we express this?
  
  We express it like this:
  
  \begin{align*}
    \tag{induction on proofs}\label{inp}
    \forall (\vdash), \forall A,\forall B,  (\deduction\ (\vdash)\ (\to)) \wedge (A \to B) \to (A \vdash B)\\
    \forall (\vdash), (\deduction\ (\vdash)\ (\to)) \to (A \to B) \to (A \vdash B)\\
    \forall (\models), (\deduction\ (\models)\ (\to)) \wedge (A \vdash B) \looparrowright (A \models B)\\
    (A \vdash B) \looparrowright \forall (\models), (\deduction\ (\models)\ (\to)) \looparrowright (A \models B)\\
  \end{align*}
  
  This deserves some explanation. Three different levels of inference are involved here (marked with numbers for the reader's benefit):
  
  \begin{align*}
    \forall (\vdash), \forall A,\forall B,  (\deduction\ (\vdash)\ (\implies{2})) \wedge (A \implies{1} B) \implies{0} (A \vdash B)\\
  \end{align*}
  
  We've already said that $(\deduction\ (\implies{1})\ (\implies{2}))$ is true. The idea now is to say that $\implies{1}$ is the \emph{minimal relation} obeying that constraint. We do this by saying that every other relation $\vdash$ obeying the same constraint is "at least as big" as $\implies{1}$, by saying that if $(A \implies{1} B)$, then $(A \vdash B)$ as well. ($(A \vdash B)$ may be true for \emph{more} things, but it can't be true for less.)
  
  This definition can also be used to write proofs by induction on the structure of proofs: If you describe an explicit $\vdash$, then the statements in $(\deduction\ (\vdash)\ (\implies{2}))$ are your induction cases.
  
  As with \emph{modus ponens}, we assert that this is a correct constraint on the true statements of IC. Again, this raises a question: Can \eqref{inp} itself be a true statement of IC?
  
  The answer, again, is no. Because $\implies{0}$ is equated with the other levels, this statement itself is a formula of the form $A \to B$, and it is not proved by $(\deduction\ (\to)\ (\to))$.
  
  
  \subsection{Uhh}
  
  We've now seen several constraints that cannot be true statements.
  
  Consider the statement "\emph{modus ponens} is a correct constraint (even though it may not be a true statement)". By the introspection principle, we should have a way to represent this statement within IC, and perhaps even have it be true.
  
  \newcommand{\icset}{\operatorname{\mathcal{IC}}}
  Let's have a symbol, $\icset$, which represents all inference rules of IC. (This will be self-containing, and that's okay.) Although we cannot soundly have $(\icset \to A) \to A$ as a truth, we are free to postulate that $\icset$ has the same \emph{set of true statements} as IC:
  
  \begin{align*}
    (\icset \to (\top \to A)) \equiv A\\
  \end{align*}
  
  We can now make statements about what inferences are allowed by $\icset$:
  
  \begin{align*}
    \icset \to modus\ ponens\\
  \end{align*}

  
  We'll have to refer to $(\deduction\ (\to)\ (\to))$ a lot. Let's define the shorthand $D_0 := (\deduction\ (\to)\ (\to))$.
  
  At this point, the \emph{truths} of IC are $D_0$ (by definition) and anything that can be deduced from it according to the inference rules, which are also $D_0$.
  
  We can also consider the statements $A$ where $(D_0 \to A)$ is true. This doesn't intrinsically include everything that's true in IC; if we added another rule ($\top \to Q$) to IC, it wouldn't give us ($\top \to (D_0 \to Q)$), because $Q$ cannot be deduced from just $D_0$, and ($\top \to Q$) does not add ($\top \to Q$) as a \emph{truth}, only $Q$. However, this category definitely contains $D_0$ and anything that can be deduced from it.
  
  Now, how about the statements $B$ where $(D_0 \to (D_0 \to B))$ is true?
  
  Clearly there's an infinite progression here. Viewing it from the outside, we believe that all of these categories contain the same statements. But we can't yet prove it within IC.
  
  The statement $\forall A, (D_0 \to A) \to A$
  
  \begin{align*}
    A\\
    D_0 \to A\\
    D_0 \to (D_0 \to A)\\
    D_0 \wedge (\top \to D_0) \to A\\
    D_0 \wedge (\top \to D_0) \to (\top \to A)\\
  \end{align*}




  \newcommand{\ic}[1]{#1}


  From the internal perspective of the calculus, the above axioms provide truth for any \emph{specific} values of the variables $A, B\dots$, but cannot prove abstractions over those variables.

\fi

\iffalse
  \subsection{Well-founded sets}

  Some discussion of well-founded sets, and how they avoid the Burali-Forti paradox.

  By convention, a \emph{set} is a predicate on formulas, where if $PF$ is true, then $F \in P$. One might expect this to cause paradoxes; this section will illustrate how it does not.

  We define \emph{well-founded sets} with a surprisingly simple rule: A well-founded set is a set for which all \emph{raisable predicates} are true. And a \emph{raisable predicate} $R$ is one where, if the $R$ is true for all members of a set, then $R$ is also true for the set itself:

  \ic{
  Raisable := R => (Q => (x => (Q x) -> (R x)) -> (R Q)).
  WellFounded := S => R => (Raisable R) -> (R S).
  }

  The first well-founded set is the empty set, which we can prove is well-founded:
  
%  \ic{
%  EmptySet := n => (x => x).
%
%  (WellFounded EmptySet) = (R => (Q => (m => (Q m) -> (R m)) -> (R Q)) -> R(n => (x => x))).
%
%  (Some axiom) proves ((R m) -> (R m))
%  (Generalization) proves (m => (R m) -> (R m))
%  (Specialization) proves (Q => (m => (Q m) -> (R m)) -> (R Q))
%                       -> (Q => (m => (Q m) -> (R m)) -> (R Q))EmptySet
%  = (m => (EmptySet m) -> (R m)) -> (R EmptySet)
%  = (m => (x => x) -> (R m)) -> (R EmptySet)
%  (Predicate unfolding) proves (Proven_a (Q => (m => (Q m) -> (R m)) -> (R Q))EmptySet) -> (m => (EmptySet m) -> (R m)) -> (R EmptySet)
%
%
%  }


  \fi

  %\printbibliography
\end{document}
