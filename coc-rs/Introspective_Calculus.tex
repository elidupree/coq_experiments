\documentclass{article}

\usepackage{tikz}
\usepackage{amsfonts}
\usepackage{amssymb}
%\usepackage[nointegrals]{wasysym}
\usepackage{mathtools}
\usepackage{mathpartir}
\usepackage{nameref}
\usepackage{xcolor}

\usepackage[english]{babel}
\usepackage[autostyle]{csquotes}
\usepackage{amsmath}
\usepackage{wasysym}
\MakeOuterQuote{"}

%\usepackage[backend=biber,style=numeric]{biblatex}
%\addbibresource{Introspective_Calculus.bib}

\title{The Introspective Calculus}
\author{Eli Dupree}
\date{\today}

\DeclareMathSymbol{\mlq}{\mathord}{operators}{``}
\DeclareMathSymbol{\mrq}{\mathord}{operators}{`'}

\begin{document}
  \maketitle
  
  \section{Introduction}
  
  This document is a bare-bones explanation of my current definitions of this calculus.
  I plan to later develop it into a full, polished explanation, once I'm more confident in its soundness.
  
  In type theory, the source of paradoxes (like Russell's paradox and Girard's paradox) is this: First you construct a self-referential claim, then you prove that claim using (rules analogous to) the following axiom of propositional logic, which is unsound for self-referential claims:
  \begin{equation*}
    \tag{implication within hypotheticals, traditional}
    (C \rightarrow (A \rightarrow B)) \rightarrow ((C \rightarrow A) \rightarrow (C \rightarrow B))
    \vspace{0.8em}
  \end{equation*}
  
  Type theories typically avoid this problem by preventing the construction of self-referential claims. However, general-purpose computation is intrinsically capable of constructing self-referential claims. Thus, any such rules must forbid many programs that would otherwise be valid.
  
  \renewcommand{\implies}[1]{\xrightarrow{#1}}
  The present work's innovation is to \emph{allow} self-referential claims, but instead weaken the above axiom. We equip the "implies" relation with a level, where $A \implies{n} B$ means "You can reason from $A$ to $B$ by a proof with \emph{no more than} $n$ levels of hypotheticals." Now the axiom becomes:
  
  \newcommand{\lzero}{0}
  \newcommand{\lsucc}[1]{\mathcal{S} #1}
  \begin{equation*}
    \tag{implication within hypotheticals, resilient}
    (C \implies{\lsucc n} (A \implies{n} B)) \implies{\lzero} ((C \implies{\lsucc n} A) \implies{\lzero} (C \implies{\lsucc n} B))
    \vspace{0.8em}
  \end{equation*}
  
  Since the result is one level higher than $A \implies{n} B$, it cannot be used later to prove the same $A \implies{n} B$ claim that it's based on. This prevents a self-referential claim from being elevated to form a self-referential \emph{proof}.
  
  This protection allows us to remove the other limitations of type theories.
  In particular, the source of the name "Introspective Calculus" is that every rule of IC can be abstracted over within IC.



  
  Section \ref{fundamentals} (\textit{\nameref{fundamentals}}) gives a formal definition of IC.  

  \section{Fundamentals}\label{fundamentals}

  \subsection{Syntax}
  \begin{align*}
     Atom :=&\ \mathrm{level\_zero} \mid \mathrm{level\_successor} \mid \mathrm{implies} \mid \mathrm{equals} \mid \mathrm{const} \mid \mathrm{fuse} \mid \mathrm{induction\_on\_proofs}\\
     F :=&\ Atom \mid (F F)
  \end{align*}

  \subsection{Notations}

  % give examples first????
  % pronunciations of the symbols
  % AB is application
  % abstractions can be viewed as forall, lambda, function, predicates
  % substution better notation?
  % implication not subscript?
  % clean up explanation of metavariable levels WRT named abstractions
%  \[ A\ B\ C \dots Y\ Z := ((\dots ((A B) C) \dots Y) Z) \]

  \newcommand{\ic}[1]{#1}
%  \newcommand{\abst}[2]{{#1} \langle \overline{\underline{ #2}}]}
  \newcommand{\nameabst}[1]{#1 \Rightarrow}
  \newcommand{\id}{\operatorname{\mathrm{id}}}
  \newcommand{\const}{\operatorname{\mathrm{const}}}
  \newcommand{\fuse}{\operatorname{\mathrm{fuse}}}
  \newcommand{\equals}{\equiv}

  \begin{align*}
    \lzero &:= \mathrm{level\_zero}\\
    \lsucc{n} &:= (\mathrm{level\_successor}\ n)\\
    (A \implies{n} B) &:= (((\mathrm{implies}\ n) A) B),\ \operatorname{right-associative}\\
    (A \equals B) &:= ((\mathrm{equals}\ A) B)\\
    \id &:= \fuse \const \const\\
  \end{align*}

  Finally, we define the \emph{named form} of abstractions, $(\nameabst{A}B),\ \operatorname{right-associative}$, where $A$ is a variable-name, and $B$ may contain instances of that name. (Perhaps we should say \emph{metavariable-name} rather than \emph{variable-name}, as these names only exist for this notation, and are not part of the formal language of IC).
  
  This is defined as in the SKI combinator calculus.

  \subsection{Axiom Definitions}
%  \setlength{\jot}{1.4em}
  \begin{gather*}
    \tag{modus ponens}\label{mp}
    \inferrule{(A \implies{n} B)\\\\A}{B}\\
  \end{gather*}
%  All remaining axioms are defined as implications ($Premise \implies{\wfz} Premise \dots \implies{\wfz} Conclusion$), which allows them to be reasoned about internally. (The external form can be derived using \eqref{mp}.) However, we still write them as $\frac{Premise\dots}{Conclusion}$ for readability.
%  \\\\
%  \setlength{\jot}{0.4em}
  ????:
  \begin{align*}
    \tag{specialization}\label{specialization}
    A &\implies{\lzero} AB\\
    \tag{equality implies implication}
    (A \equals B) &\implies{\lzero} (A \implies{\lzero} B)\\
%    \tag{truth of foralls}
%    A &\implies{\wfz} (\abst{A})\\
%    \tag{extensionality}\label{extensionality}
%    (\nameabst{C} (AC \equals BC)) \implies{\lzero} (A \equals B)\\
  \end{align*}
%  Definitional equality:
%  \begin{align*}
%%    \tag{symmetry}
%%    \inferrule{A \equals B}{B \equals A}\\
%  \end{align*}
  Elementary function definitions:
%  \setlength{\jot}{0.1em}
  \begin{align*}
    \const A\,B &\equals A\\
    \fuse A\,B\,C &\equals (AC)(BC)\\
  \end{align*}
  Implication:
  \begin{align*}
    \tag{weakening}
    B \implies{\lzero} (A \implies{\lzero} B)\\
    \tag{level weakening}
    (A \implies{n} B) \implies{\lzero} (A \implies{\lsucc n} B)\\
    \tag{implication within hypotheticals}
    (C \implies{\lsucc n} (A \implies{n} B)) \implies{\lzero} ((C \implies{\lsucc n} A) \implies{\lzero} (C \implies{\lsucc n} B))\\
  \end{align*}
  More stuff:
  \begin{align*}
    \tag{reflexivity}\label{eq_refl}
    A &\equals A\\
    (A \equals B) C &\equals (CA \equals CB)\\
  \end{align*}

  \subsection{Internal Axioms}

  We now define \emph{internal} representations of the above axioms.

  From the internal perspective of the calculus, the above axioms provide truth for any \emph{specific} values of the variables $A, B\dots$, but cannot prove abstractions over those variables.
  So, for each axiom, we also create an internal form, by representing the metavariables using abstractions, and the premises using implication (at level $\lzero$).
  For example, (modus ponens) is represented as:

  \begin{equation*}
    \mathrm{``modus\ ponens"} := \nameabst{A} \nameabst{B} \nameabst{n} (A \implies{n} B) \implies{\lzero} A \implies{\lzero} B
  \end{equation*}
  
  The above is merely a notation, saying that the right-hand side \emph{is} the statement of "modus ponens". Rather than postulate each of these generalized axioms individually, we make the following comprehensive rule:
  
  \setlength{\jot}{0em}
  \begin{align*}
    \tag{proof induction is true}\label{indt}
    \mathrm{induction\_on\_proofs}\\
    \tag{definition of proof induction}\label{indd}
    \mathrm{induction\_on\_proofs} \equals \nameabst{P} (P \equals (&\nameabst{R}\\
      &\nameabst{n}\\
      &R\mathrm{``modus\ ponens"} \implies{\lzero}\\
      &\dots \implies{\lzero}\\
      &R\mathrm{``specialization"} \implies{\lzero}\\
      &R\ \mathrm{induction\_on\_proofs} \implies{\lzero}\\
      &(\nameabst{A}\nameabst{B}RA\implies{n}R(AB)) \implies{\lzero}\\
      &(\nameabst{A}\nameabst{B}R(A\implies{\lzero}B)\implies{n}RA\implies{n}RB) \implies{\lsucc{n}}\\
      &RP))\\
  \end{align*}

  (We would like the definition of proof induction to be a notation like the other axioms, but that would make it a self-containing formula. IC can actually permit self containing formulas, but we understand that the reader may be skeptical of a self containing axiom! Thus, we choose to represent it as an atom with a definitional-equality.)
  
  Observe that this rule immediately proves any of the individual generalized axioms. For example, "modus ponens" is proved by specializing this rule with $P := \mathrm{``modus\ ponens"}$, because the premise $R\mathrm{``modus\ ponens"}$ proves the conclusion $RP$.
  
  But the more interesting feature of this rule is the other direction of implication: If $P$, then $P$ is reachable by induction from the listed axioms. This essentially says that our list of axioms is \emph{exhaustive} – there are no other axioms – and the rule makes that fact visible to internal logic.
  
With such a powerful rule, one should immediately worry if it proves a contradiction. After all, the generalized axioms are not strictly the same objects as the external axioms, and the axiom \eqref{indd} is not in the list at all. However, any statement you can prove using an external axiom is a specialization of the generalized form, and thus reachable by induction from the generalized axioms. And because definitionally-equal formulas are indistinguishable to the internal logic, \eqref{indd} is just a specialization of \eqref{eq_refl}.

  \section{Examples}\label{structure}

  We can define the conventional logical connectives in terms of the above rules:

  \setlength{\jot}{0.4em}
  \begin{align*}
    \tag{false/absurdity}
    \bot &:= (\nameabst{P}{P})\\
    \tag{negation}
    \neg_{n} P &:= ({P \implies{n} \bot})\\
    \mathrm{not} &:= (\nameabst{P} \neg P)\\
%    \tag{conjunction}
%    P \land Q &:= (\nameabst{R} (P \implies{\wfz} Q \implies{\wfz} R) \implies{\wfz} R)\\
%    \mathrm{and} &:= (\nameabst{P}\nameabst{Q} P \land Q)\\
%    \tag{disjunction}
%    P \lor Q &:= (\nameabst{R} (P \implies R) \implies (Q \implies R) \implies R)\\
%    \mathrm{or} &:= (\nameabst{P}\nameabst{Q} P \lor Q)\\
%    \tag{existential quantification}
%    \exists x, P(x) &:= (\nameabst{R} (\nameabst{x} P(x) \implies R) \implies R)\\
  \end{align*}

%  And we can prove some tautologies:
%  \begin{align*}
%  (P \land Q)
%  \end{align*}
\iffalse
  \subsection{Well-founded sets}

  Some discussion of well-founded sets, and how they avoid the Burali-Forti paradox.

  By convention, a \emph{set} is a predicate on formulas, where if $PF$ is true, then $F \in P$. One might expect this to cause paradoxes; this section will illustrate how it does not.

  We define \emph{well-founded sets} with a surprisingly simple rule: A well-founded set is a set for which all \emph{raisable predicates} are true. And a \emph{raisable predicate} $R$ is one where, if the $R$ is true for all members of a set, then $R$ is also true for the set itself:

  \ic{
  Raisable := R => (Q => (x => (Q x) -> (R x)) -> (R Q)).
  WellFounded := S => R => (Raisable R) -> (R S).
  }

  The first well-founded set is the empty set, which we can prove is well-founded:
  
%  \ic{
%  EmptySet := n => (x => x).
%
%  (WellFounded EmptySet) = (R => (Q => (m => (Q m) -> (R m)) -> (R Q)) -> R(n => (x => x))).
%
%  (Some axiom) proves ((R m) -> (R m))
%  (Generalization) proves (m => (R m) -> (R m))
%  (Specialization) proves (Q => (m => (Q m) -> (R m)) -> (R Q))
%                       -> (Q => (m => (Q m) -> (R m)) -> (R Q))EmptySet
%  = (m => (EmptySet m) -> (R m)) -> (R EmptySet)
%  = (m => (x => x) -> (R m)) -> (R EmptySet)
%  (Predicate unfolding) proves (Proven_a (Q => (m => (Q m) -> (R m)) -> (R Q))EmptySet) -> (m => (EmptySet m) -> (R m)) -> (R EmptySet)
%
%
%  }

  \section{Consistency}\label{consistency}
  
  We regard a proposition $P$ as "proven" if it is \emph{eventually true} within IC, i.e.
  
  \newcommand{\eventually}{\operatorname{\mathrm{Eventually}}}
  
  \[ \eventually P := \exists n, \clocksub{+n} P \]
  
  This is a meta-theoretical definition; if we use our internal definition of $\exists$, which contains 2 nested abstractions, then you can never prove $(\eventually P)$, only $\clocksub{+2}(\eventually P)$.
  
  That said, since every axiom of IC can be applied within clocks, we could view the inside of $\clocksub{+n}$ as being another instance of the calculus – call it IC$_{+n}$ – which adds the axiom "if $\clocksub{+n} P$ is true in IC, then $P$ is true in IC$_{+n}$". If we move to IC$_{+2}$, we \emph{can} be comfortable with an internal definition of $\eventually$. Thus, IC can function as its own metatheory, just with a clock offset.
  
  By the axiom \eqref{lne}, anything that's eventually true is also eternally true, in the sense that you can "wait" for an IC$_{+n}$ where P is as old as you want:
  
%  \[ \nameabst{n} \wellfounded n \implies \eventually P \implies \eventually \clocksub{-n} P \]
  
  One might ask: What if you can't prove $(\eventually P)$, but only $\eventually (\eventually P)$? One might hope that $\eventually (\eventually P)$ implies $(\eventually P)$, but it does not – it only implies $\clocksub{+constant}(\eventually P)$. But could we also regard that as "proving $P$"? Unfortunately, if we did, we would then want to extend it to $\eventually (\eventually (\eventually P))$, and so forth. For the sake of having a single definition, the answer must be \emph{no}. But the purpose of including the entire well-founded hierarchy is that you don't \emph{need} to.
  
  Intuitively, the only way to prove $(\eventually P)$ is to exhibit a \emph{specific} $n$ where you can prove $\clocksub{+n} P$. Assuming this is true, you can simply take that value of $n$ Unfortunately, you can't prove this within IC, because the internal logic of IC doesn't know that there aren't extra axioms that could make $\eventually P$ true for other reasons. However, what you \emph{can} do is to define a predicate
  
  \newcommand{\provable}{\operatorname{\mathrm{Provable}}}
  
  \[\provable P := \dots\]
  
  which is true for anything that can be proved from the actual axioms of IC. (You define this as an induction predicate, with the axioms of IC as cases; we omit the definition because it is long.)
  
  A digression on the properties of $\provable$: Meta-theoretically, we don't think you can prove anything that's not $\eventually \provable$. But this is impossible to prove inside IC, for the same reasons as above. In fact, the proposition $(P \implies \eventually (\provable P))$ is \emph{false} within IC, because it is self-contradictory. (If true, it would be a statement that was true but not provable from the axioms!)
  
%  We also cannot prove $(\provable P) \implies P$, even though we believe that all provable statements are true; but fortunately, $(\provable P) \implies (\eventually P)$ is a trivial corollary.
  
  (All of the following is conjecture, but I expect it to be true, at least once I have cleaned up any definitional mistakes:)
  
  With the provability predicate, we can prove:
  
%  \[ \nameabst{P} \eventually (\provable (\eventually P)) \implies \eventually  P \]
  
  This theorem has an immediate corollary that is very significant:
  
%  \[ \nameabst{P} \eventually (\provable (\eventually \bot)) \implies \eventually \bot \]
\fi

  %\printbibliography
\end{document}
