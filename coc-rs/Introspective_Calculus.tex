\documentclass{article}

\usepackage{tikz}
\usepackage{amsfonts}
\usepackage{amssymb}
%\usepackage[nointegrals]{wasysym}
\usepackage{mathtools}
\usepackage{mathpartir}
\usepackage{nameref}
\usepackage{xcolor}

\usepackage[english]{babel}
\usepackage[autostyle]{csquotes}
\usepackage{amsmath}
\usepackage{wasysym}
\MakeOuterQuote{"}

%\usepackage[backend=biber,style=numeric]{biblatex}
%\addbibresource{Introspective_Calculus.bib}

\title{The Introspective Calculus}
\author{Eli Dupree}
\date{\today}

\DeclareMathSymbol{\mlq}{\mathord}{operators}{``}
\DeclareMathSymbol{\mrq}{\mathord}{operators}{`'}

\begin{document}
  \maketitle
  
  \section{Introduction}
  
  This document is a bare-bones explanation of my current definitions of this calculus.
  I plan to later develop it into a full, polished explanation, once I'm more confident in its soundness.
  
  In type theory, the source of paradoxes (like Russell's paradox and Girard's paradox) is this: First you construct a self-referential claim, then you prove that claim using (rules analogous to) the following axiom of propositional logic, which is unsound for self-referential claims:
  \begin{equation*}
    \tag{implication under hypotheticals, traditional}
    (C \rightarrow (A \rightarrow B)) \rightarrow ((C \rightarrow A) \rightarrow (C \rightarrow B))
    \vspace{0.8em}
  \end{equation*}
  
  Type theories typically avoid this problem by preventing the construction of self-referential claims. However, general-purpose computation is intrinsically capable of constructing self-referential claims. Thus, any such rules must forbid many programs that would otherwise be valid.
  
  \renewcommand{\implies}[1]{\rightarrow_{\hspace{-0.04em}#1}}
  The present work's innovation is to \emph{allow} self-referential claims, but instead weaken the above axiom. We equip the "implies" relation with a level, where $A \implies{n} B$ means "You can reason from $A$ to $B$ by a proof with \emph{no more than} $n$ levels of hypotheticals." Now the axiom becomes:
  
  \newcommand{\lzero}{0}
  \newcommand{\lsucc}[1]{\mathcal{S} #1}
  \begin{equation*}
    \tag{implication under hypotheticals, resilient}
    (C \implies{\lsucc n} (A \implies{n} B)) \implies{\lzero} ((C \implies{\lsucc n} A) \implies{\lzero} (C \implies{\lsucc n} B))
    \vspace{0.8em}
  \end{equation*}
  
  Since the result is one level higher than $A \implies{n} B$, it cannot be used later to prove the same $A \implies{n} B$ claim that it's based on. This prevents a self-referential claim from being elevated to form a self-referential \emph{proof}.
  
  This protection allows us to remove the other limitations of type theories.
  In particular, the source of the name "Introspective Calculus" is that every rule of IC can be abstracted over within IC.



  
  Section \ref{fundamentals} (\textit{\nameref{fundamentals}}) gives a formal definition of IC.  

  \section{Fundamentals}\label{fundamentals}

  \subsection{Syntax}
  \begin{align*}
     Atom :=&\ \mathrm{level\_zero} \mid \mathrm{level\_successor} \mid \mathrm{implies} \mid \mathrm{equals} \mid \mathrm{substitute\_in} \mid \mathrm{axiom\_says}\\
     F :=&\ \mathrm{atom}\ Atom \mid \mathrm{usage} \mid \mathrm{abstraction}\ F \mid \mathrm{pop}\ F \mid (F F)
  \end{align*}

  \subsection{Notations}
  
%  \[ A\ B\ C \dots Y\ Z := ((\dots ((A B) C) \dots Y) Z) \]

  \newcommand{\ic}[1]{#1}
  \newcommand{\abst}[1]{#1\!\Leftarrow}
  \newcommand{\context}[2]{\mlq#1/#2\mrq}
  \newcommand{\variable}[1]{{\mathcal{V}_{\mlq\hspace{-0.06em}#1\hspace{-0.06em}\mrq}}}
  \newcommand{\clocksub}[1]{\text{\clock}_{\!#1}}
  \newcommand{\nameabst}[1]{#1 \Rightarrow}
  \newcommand{\axiom}[2]{\mathrm{Axiom}\ #1\ \mathrm{says}\ #2}
  \newcommand{\axiomatic}[1]{\infty #1}
%  \newcommand{\usage}{\mathcal{V}}
  \newcommand{\usage}{\circ}
  \newcommand{\pop}[1]{#1\triangleleft}
  \newcommand{\subst}[3]{#1^{[{#2}{/}{#3}]}}

  \begin{align*}
    \lzero &:= \mathrm{atom}\ \mathrm{level\_zero}\\
    \lsucc{n} &:= ((\mathrm{atom}\ \mathrm{level\_successor}) n)\\
    (A \implies{n} B) &:= ((((\mathrm{atom}\ \mathrm{implies}) A) n) B),\ \operatorname{right-associative}\\
    (A \equiv B) &:= (((\mathrm{atom}\ \mathrm{equals}) A) B)\\
    \subst{A}{B}{C} &:= ((((\mathrm{atom}\ \mathrm{substitute\_in}) A) B) C)\\
    \axiom{A}{B} &:= (((\mathrm{atom}\ \mathrm{axiom\_says}) A) B)\\
    \usage &:= \mathrm{usage}\\
    \abst{A} &:= \mathrm{abstraction}\ A\\
    \pop{A} &:= \mathrm{pop}\ A\\
  \end{align*}

  Finally, we define the \emph{named form} of abstractions, $(\nameabst{A}B),\ \operatorname{right-associative}$, where $A$ is a variable-name, and $B$ may contain instances of that name. (Perhaps we should say \emph{metavariable-name} rather than \emph{variable-name}, as these names only exist for this notation, and are not part of the formal language of IC).
  
  This is defined as $(\abst{B'})$, where $B'$ is $B$ with the following changes:
  \begin{itemize}
    \item Replace all instances of $A$ with the formula $\usage$.
    \item Insert the minimum collection of pops such that, according to the substitution axioms below, $\subst{B'}{\lzero}{C}$ will place $C$ at the locations of those instances of $A$.
  \end{itemize}

  \subsection{Axiom Definitions}
  \setlength{\jot}{1.4em}
  \begin{gather*}
    \tag{modus ponens}\label{mp}
    \inferrule{(A \implies{n} B)\\\\A}{B}\\
  \end{gather*}
%  All remaining axioms are defined as implications ($Premise \implies{\wfz} Premise \dots \implies{\wfz} Conclusion$), which allows them to be reasoned about internally. (The external form can be derived using \eqref{mp}.) However, we still write them as $\frac{Premise\dots}{Conclusion}$ for readability.
%  \\\\
  Implication:
  \begin{align*}
    \tag{weakening}
    \inferrule{B}{A \implies{\lzero} B}\\
    \tag{level weakening}
    \inferrule{A \implies{n} B}{A \implies{\lsucc n} B}\\
    \tag{implication within hypotheticals}
    \inferrule{C \implies{\lsucc n} (A \implies{n} B)\\\\C \implies{\lsucc n} A}{C \implies{\lsucc n} B}\\
  \end{align*}
  \setlength{\jot}{0.4em}
  Definitional equality:
  \begin{align*}
%    \tag{symmetry}
%    \inferrule{A \equiv B}{B \equiv A}\\
    \tag{implication}
    (A \equiv B) &\implies{\lzero} (A \implies{\lzero} B)\\
    \tag{indistinguishability}
    (A \equiv B) &\equiv (\nameabst{P} PA \equiv PB)\\
  \end{align*}
  Substitution:
  \begin{align*}
    \subst{\usage}{\lzero}{C} &\equiv C & \subst{\usage}{\lsucc{v}}{C} &\equiv \usage\\
    \subst{(\pop{A})}{\lzero}{C} &\equiv (\pop{A}) & \subst{(\pop{A})}{\lsucc{v}}{C} &\equiv (\pop{\subst{A}{v}{C}})\\
    \subst{(Atom\,A)}{v}{C} &\equiv (Atom\,A)\\
    \subst{(AB)}{v}{C} &\equiv \subst{A}{v}{C}\subst{B}{v}{C}\\
    \subst{(\abst{A})}{v}{C} &\equiv (\abst{\subst{A}{\lsucc{v}}{C}})\\
  \end{align*}
  Abstraction:
  \begin{align*}
    \tag{unfolding}
    (\abst{A})B \equiv \subst{A}{\lzero}{B}\\
%    \tag{truth of foralls}
%    A &\implies{\wfz} (\abst{A})\\
    \tag{specialization}\label{specialization}
    (\abst{A}) \implies{\lzero} (\abst{A})B\\
%    \tag{induction}
%    \inferrule{P\ Atom\dots\\\\\nameabstraction{A} \nameabstraction{B} P A \implies P B \implies P (A B)}{P C}\\
  \end{align*}
  Axiom rules:
  \setlength{\jot}{1.4em}
  \begin{gather*}
    \tag{successor axioms}\label{axs}
    \inferrule{\axiom{A}{B}}{\axiom{(\lsucc A)}{(\axiom{A}{B})}}\\
    \tag{axioms say nothing else}\label{axu}
    \inferrule{\axiom{A}{B}\\\\\axiom{A}{C}}{B \equiv C}\\
    \tag{there are no other axioms}\label{axe}
    \inferrule{
      R\mathrm{``modus\ ponens"}\\\\
      \dots\\\\
      R\mathrm{``there\ are\ no\ other\ axioms"}\\\\
      R\mathrm{``only\ axioms\ prove\ things"}\\\\
      \nameabst{a} Ra \implies{n} R(\lsucc a)\\\\
      \axiom{A}{B}
    }{RA}\\
    \tag{only axioms prove things}
    \inferrule{
      \nameabst{A}\nameabst{B}(\axiom{A}{B})\implies{n}RB\\\\
      \nameabst{A}\nameabst{B}R(\abst{A})\implies{n}R((\abst{A})B)\\\\
      \nameabst{A}\nameabst{B}R(A\implies{\lzero}B)\implies{n}RA\implies{n}RB\\\\
      P
    }{RP}\\
%    \inferrule{\axiomatic{A}}{\axiomatic{\axiomatic{A}}}\\
%    \tag{induction on axioms}\label{axe}
%    \inferrule{\axiom{A}{B}\\\\P\text{``modus ponens"}\\\\\dots\\\\P\text{``induction on axioms"}\\\\(\nameabstraction{a} Pa \implies P(\wfsucc a))}{PA}\\
  \end{gather*}

  \subsection{Internal Axioms}

  We now define \emph{internal} versions of the above axioms.

  From the internal perspective of the calculus, the above axioms provide truth for any \emph{specific} values of the variables $A, B\dots$, but cannot prove abstractions over those variables.
  So, for each axiom, we also create an internal form, by representing the metavariables using abstractions, and the premises using implication (at level $\lzero$).
  For example, (modus ponens) is represented as:

  \begin{equation*}
    \tag{modus ponens, generalized}\label{mpg}
    \nameabst{A} \nameabst{B} \nameabst{n} (A \implies{n} B) \implies{\lzero} A \implies{\lzero} B
  \end{equation*}
  
  (Observe that any usage of an external axiom can also be achieved by combining its generalized form with \eqref{specialization}, the substitution rules, and \eqref{mp}.)

  Now we make one more coup: We also represent the \emph{fact that this is an axiom} internally, by adding the symbol "modus ponens" as a possible atom, and adding the following axiom:

  \begin{equation*}
    \tag{modus ponens, internalized}\label{mpi}
    \axiom{
      \mathrm{``modus\ ponens"}\\
    }{
      (\nameabst{A} \nameabst{B} \nameabst{n} (A \implies{n} B) \implies{\lzero} A \implies{\lzero} B)
    }\\
  \end{equation*}

  Of course, \eqref{mpi} is now another axiom that does not have an explicit internal form!
  Fortunately, we do not need an infinite regression of \emph{explicit} definitions. Since \eqref{mpi} has no metavariables or premises, \eqref{axs} can take care of it, giving us:

  \begin{equation*}
    \axiom{(\lsucc\mathrm{``modus\ ponens"})}{(
      \axiom{\mathrm{``modus\ ponens"}}{
        (\nameabst{A} \nameabst{B} \nameabst{n} (A \implies{n} B) \implies{\lzero} A \implies{\lzero} B)
      }
    )}\\
  \end{equation*}

  and so forth.

  \section{Examples}\label{structure}

  We can define the conventional logical connectives in terms of the above rules:

  \setlength{\jot}{0.4em}
  \begin{align*}
    \tag{false/absurdity}
    \bot &:= (\nameabst{P}{P})\\
    \tag{negation}
    \neg_{n} P &:= ({P \implies{n} \bot})\\
    \mathrm{not} &:= (\nameabst{P} \neg P)\\
%    \tag{conjunction}
%    P \land Q &:= (\nameabst{R} (P \implies{\wfz} Q \implies{\wfz} R) \implies{\wfz} R)\\
%    \mathrm{and} &:= (\nameabst{P}\nameabst{Q} P \land Q)\\
%    \tag{disjunction}
%    P \lor Q &:= (\nameabst{R} (P \implies R) \implies (Q \implies R) \implies R)\\
%    \mathrm{or} &:= (\nameabst{P}\nameabst{Q} P \lor Q)\\
%    \tag{existential quantification}
%    \exists x, P(x) &:= (\nameabst{R} (\nameabst{x} P(x) \implies R) \implies R)\\
  \end{align*}

%  And we can prove some tautologies:
%  \begin{align*}
%  (P \land Q)
%  \end{align*}
\iffalse
  \subsection{Well-founded sets}

  Some discussion of well-founded sets, and how they avoid the Burali-Forti paradox.

  By convention, a \emph{set} is a predicate on formulas, where if $PF$ is true, then $F \in P$. One might expect this to cause paradoxes; this section will illustrate how it does not.

  We define \emph{well-founded sets} with a surprisingly simple rule: A well-founded set is a set for which all \emph{raisable predicates} are true. And a \emph{raisable predicate} $R$ is one where, if the $R$ is true for all members of a set, then $R$ is also true for the set itself:

  \ic{
  Raisable := R => (Q => (x => (Q x) -> (R x)) -> (R Q)).
  WellFounded := S => R => (Raisable R) -> (R S).
  }

  The first well-founded set is the empty set, which we can prove is well-founded:
  
%  \ic{
%  EmptySet := n => (x => x).
%
%  (WellFounded EmptySet) = (R => (Q => (m => (Q m) -> (R m)) -> (R Q)) -> R(n => (x => x))).
%
%  (Some axiom) proves ((R m) -> (R m))
%  (Generalization) proves (m => (R m) -> (R m))
%  (Specialization) proves (Q => (m => (Q m) -> (R m)) -> (R Q))
%                       -> (Q => (m => (Q m) -> (R m)) -> (R Q))EmptySet
%  = (m => (EmptySet m) -> (R m)) -> (R EmptySet)
%  = (m => (x => x) -> (R m)) -> (R EmptySet)
%  (Predicate unfolding) proves (Proven_a (Q => (m => (Q m) -> (R m)) -> (R Q))EmptySet) -> (m => (EmptySet m) -> (R m)) -> (R EmptySet)
%
%
%  }

  \section{Consistency}\label{consistency}
  
  We regard a proposition $P$ as "proven" if it is \emph{eventually true} within IC, i.e.
  
  \newcommand{\eventually}{\operatorname{\mathrm{Eventually}}}
  
  \[ \eventually P := \exists n, \clocksub{+n} P \]
  
  This is a meta-theoretical definition; if we use our internal definition of $\exists$, which contains 2 nested abstractions, then you can never prove $(\eventually P)$, only $\clocksub{+2}(\eventually P)$.
  
  That said, since every axiom of IC can be applied within clocks, we could view the inside of $\clocksub{+n}$ as being another instance of the calculus – call it IC$_{+n}$ – which adds the axiom "if $\clocksub{+n} P$ is true in IC, then $P$ is true in IC$_{+n}$". If we move to IC$_{+2}$, we \emph{can} be comfortable with an internal definition of $\eventually$. Thus, IC can function as its own metatheory, just with a clock offset.
  
  By the axiom \eqref{lne}, anything that's eventually true is also eternally true, in the sense that you can "wait" for an IC$_{+n}$ where P is as old as you want:
  
%  \[ \nameabst{n} \wellfounded n \implies \eventually P \implies \eventually \clocksub{-n} P \]
  
  One might ask: What if you can't prove $(\eventually P)$, but only $\eventually (\eventually P)$? One might hope that $\eventually (\eventually P)$ implies $(\eventually P)$, but it does not – it only implies $\clocksub{+constant}(\eventually P)$. But could we also regard that as "proving $P$"? Unfortunately, if we did, we would then want to extend it to $\eventually (\eventually (\eventually P))$, and so forth. For the sake of having a single definition, the answer must be \emph{no}. But the purpose of including the entire well-founded hierarchy is that you don't \emph{need} to.
  
  Intuitively, the only way to prove $(\eventually P)$ is to exhibit a \emph{specific} $n$ where you can prove $\clocksub{+n} P$. Assuming this is true, you can simply take that value of $n$ Unfortunately, you can't prove this within IC, because the internal logic of IC doesn't know that there aren't extra axioms that could make $\eventually P$ true for other reasons. However, what you \emph{can} do is to define a predicate
  
  \newcommand{\provable}{\operatorname{\mathrm{Provable}}}
  
  \[\provable P := \dots\]
  
  which is true for anything that can be proved from the actual axioms of IC. (You define this as an induction predicate, with the axioms of IC as cases; we omit the definition because it is long.)
  
  A digression on the properties of $\provable$: Meta-theoretically, we don't think you can prove anything that's not $\eventually \provable$. But this is impossible to prove inside IC, for the same reasons as above. In fact, the proposition $(P \implies \eventually (\provable P))$ is \emph{false} within IC, because it is self-contradictory. (If true, it would be a statement that was true but not provable from the axioms!)
  
%  We also cannot prove $(\provable P) \implies P$, even though we believe that all provable statements are true; but fortunately, $(\provable P) \implies (\eventually P)$ is a trivial corollary.
  
  (All of the following is conjecture, but I expect it to be true, at least once I have cleaned up any definitional mistakes:)
  
  With the provability predicate, we can prove:
  
%  \[ \nameabst{P} \eventually (\provable (\eventually P)) \implies \eventually  P \]
  
  This theorem has an immediate corollary that is very significant:
  
%  \[ \nameabst{P} \eventually (\provable (\eventually \bot)) \implies \eventually \bot \]
\fi

  %\printbibliography
\end{document}
